{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52269083, -0.22415945, -0.33585399, ...,  0.69791514,\n",
       "         1.19434575,  0.81851722],\n",
       "       [ 0.12289801,  0.23949905,  0.36805204, ...,  1.05240722,\n",
       "         1.19434575,  0.81851722],\n",
       "       [-0.61547699, -1.04043621, -0.2512704 , ...,  0.69791514,\n",
       "         0.59526365,  0.25281025],\n",
       "       ...,\n",
       "       [ 1.52002204,  0.64506514,  0.12458575, ...,  1.05240722,\n",
       "         1.02465893,  0.81851722],\n",
       "       [ 1.19234002,  0.9515723 ,  1.34588799, ..., -0.7473218 ,\n",
       "        -0.3527519 ,  0.81851722],\n",
       "       [ 1.03877276,  1.59472997,  1.1641744 , ..., -0.7473218 ,\n",
       "         0.57614401,  0.81851722]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "datax = pickle.load(open(\"../data/tmp/datax\", \"rb\"))\n",
    "datay = pickle.load(open(\"../data/tmp/datay\", \"rb\"))\n",
    "datax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    8,    18,    78,   295,  1482,  7483],\n",
       "        [    8,    18,    52,    41,   595,  3130],\n",
       "        [    8,    18,    78,   295,   704,  3690],\n",
       "        ...,\n",
       "        [   17,     5,    86,   334,  3478, 16877],\n",
       "        [   17,     5,    86,   136,  1749,  8798],\n",
       "        [   17,     5,    86,   136,  2915, 14337]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "x_tensor = torch.tensor(datax, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(datay, dtype=torch.long)\n",
    "y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChainModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        embed_dim: int,\n",
    "        num_phylum: int,\n",
    "        num_class: int,\n",
    "        num_order: int,\n",
    "        num_family: int,\n",
    "        num_genus: int,\n",
    "        num_species: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # 公共特征提取层\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # 第 1 层级：phylum\n",
    "        self.phylum_head = nn.Linear(hidden_dim, num_phylum)\n",
    "        self.phylum_embed = nn.Embedding(num_phylum, embed_dim)\n",
    "\n",
    "        # 第 2 层级：class\n",
    "        self.class_head = nn.Linear(hidden_dim + embed_dim, num_class)\n",
    "        self.class_embed = nn.Embedding(num_class, embed_dim)\n",
    "\n",
    "        # 第 3 层级：order\n",
    "        self.order_head = nn.Linear(hidden_dim + embed_dim, num_order)\n",
    "        self.order_embed = nn.Embedding(num_order, embed_dim)\n",
    "\n",
    "        # 第 4 层级：family\n",
    "        self.family_head = nn.Linear(hidden_dim + embed_dim, num_family)\n",
    "        self.family_embed = nn.Embedding(num_family, embed_dim)\n",
    "\n",
    "        # 第 5 层级：genus\n",
    "        self.genus_head = nn.Linear(hidden_dim + embed_dim, num_genus)\n",
    "        self.genus_embed = nn.Embedding(num_genus, embed_dim)\n",
    "\n",
    "        # 第 6 层级：species\n",
    "        self.species_head = nn.Linear(hidden_dim + embed_dim, num_species)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y=None,\n",
    "        teacher_forcing: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        x: [batch_size, input_dim] 原始输入特征\n",
    "        y: [batch_size, 6] 各层级的真值 (phylum, class, order, family, genus, species)\n",
    "        teacher_forcing: 训练时是否使用真值 (True) 还是使用预测值 (False)\n",
    "\n",
    "        返回：\n",
    "          logits_phylum, logits_class, logits_order, logits_family, logits_genus, logits_species\n",
    "        \"\"\"\n",
    "        # 先提取共享特征\n",
    "        shared_features = self.shared_layers(x)\n",
    "\n",
    "        # ====================\n",
    "        # 第 1 层级: phylum\n",
    "        # ====================\n",
    "        logits_phylum = self.phylum_head(shared_features)\n",
    "        if (y is not None) and teacher_forcing:\n",
    "            # 训练时：使用真值做 embedding\n",
    "            phylum_emb = self.phylum_embed(y[:, 0])\n",
    "        else:\n",
    "            # 推理或不采用 teacher forcing 时：使用预测做 embedding\n",
    "            phylum_pred = logits_phylum.argmax(dim=1)\n",
    "            phylum_emb = self.phylum_embed(phylum_pred)\n",
    "\n",
    "        # ====================\n",
    "        # 第 2 层级: class\n",
    "        # ====================\n",
    "        class_in = torch.cat([shared_features, phylum_emb], dim=1)\n",
    "        logits_class = self.class_head(class_in)\n",
    "        if (y is not None) and teacher_forcing:\n",
    "            class_emb = self.class_embed(y[:, 1])\n",
    "        else:\n",
    "            class_pred = logits_class.argmax(dim=1)\n",
    "            class_emb = self.class_embed(class_pred)\n",
    "\n",
    "        # ====================\n",
    "        # 第 3 层级: order\n",
    "        # ====================\n",
    "        order_in = torch.cat([shared_features, class_emb], dim=1)\n",
    "        logits_order = self.order_head(order_in)\n",
    "        if (y is not None) and teacher_forcing:\n",
    "            order_emb = self.order_embed(y[:, 2])\n",
    "        else:\n",
    "            order_pred = logits_order.argmax(dim=1)\n",
    "            order_emb = self.order_embed(order_pred)\n",
    "\n",
    "        # ====================\n",
    "        # 第 4 层级: family\n",
    "        # ====================\n",
    "        family_in = torch.cat([shared_features, order_emb], dim=1)\n",
    "        logits_family = self.family_head(family_in)\n",
    "        if (y is not None) and teacher_forcing:\n",
    "            family_emb = self.family_embed(y[:, 3])\n",
    "        else:\n",
    "            family_pred = logits_family.argmax(dim=1)\n",
    "            family_emb = self.family_embed(family_pred)\n",
    "\n",
    "        # ====================\n",
    "        # 第 5 层级: genus\n",
    "        # ====================\n",
    "        genus_in = torch.cat([shared_features, family_emb], dim=1)\n",
    "        logits_genus = self.genus_head(genus_in)\n",
    "        if (y is not None) and teacher_forcing:\n",
    "            genus_emb = self.genus_embed(y[:, 4])\n",
    "        else:\n",
    "            genus_pred = logits_genus.argmax(dim=1)\n",
    "            genus_emb = self.genus_embed(genus_pred)\n",
    "\n",
    "        # ====================\n",
    "        # 第 6 层级: species\n",
    "        # ====================\n",
    "        species_in = torch.cat([shared_features, genus_emb], dim=1)\n",
    "        logits_species = self.species_head(species_in)\n",
    "\n",
    "        return (\n",
    "            logits_phylum,\n",
    "            logits_class,\n",
    "            logits_order,\n",
    "            logits_family,\n",
    "            logits_genus,\n",
    "            logits_species\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  20,  290,  651, 1757,    9,  331,   86,  814, 2815, 1624,  183,\n",
       "        131,   21, 1541,  271,   16,   32, 4861,  614])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "datay[:, 0]\n",
    "unique_elements, num_phylum = np.unique(datay[:, 0], return_counts=True)\n",
    "num_phylum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "44\n",
      "87\n",
      "335\n",
      "3692\n",
      "17665\n"
     ]
    }
   ],
   "source": [
    "num_phylum=datay[:, 0].max()+1\n",
    "print(num_phylum)\n",
    "num_class=datay[:, 1].max()+1\n",
    "print(num_class)\n",
    "num_order=datay[:, 2].max()+1\n",
    "print(num_order)\n",
    "num_family=datay[:, 3].max()+1\n",
    "print(num_family)\n",
    "num_genus=datay[:, 4].max()+1\n",
    "print(num_genus)\n",
    "num_species=datay[:, 5].max()+1\n",
    "print(num_species)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 16.5900\n",
      "Epoch [2/20], Loss: 8.7436\n",
      "Epoch [3/20], Loss: 5.2702\n",
      "Epoch [4/20], Loss: 3.7572\n",
      "Epoch [5/20], Loss: 2.9236\n",
      "Epoch [6/20], Loss: 2.3807\n",
      "Epoch [7/20], Loss: 2.0191\n",
      "Epoch [8/20], Loss: 1.7803\n",
      "Epoch [9/20], Loss: 1.5732\n",
      "Epoch [10/20], Loss: 1.4327\n",
      "Epoch [11/20], Loss: 1.3338\n",
      "Epoch [12/20], Loss: 1.2526\n",
      "Epoch [13/20], Loss: 1.1625\n",
      "Epoch [14/20], Loss: 1.1167\n",
      "Epoch [15/20], Loss: 1.0588\n",
      "Epoch [16/20], Loss: 1.0108\n",
      "Epoch [17/20], Loss: 0.9638\n",
      "Epoch [18/20], Loss: 0.9379\n",
      "Epoch [19/20], Loss: 0.8875\n",
      "Epoch [20/20], Loss: 0.8763\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_dim = x_tensor.shape[1]  # x_tensor.shape[1] 应该是特征数 D\n",
    "hidden_dim = 1024              # 隐藏层维度\n",
    "embed_dim = 128                 # 用于上一层级分类结果的 embedding 维度\n",
    "\n",
    "model = ChainModel(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    embed_dim=embed_dim,\n",
    "    num_phylum=num_phylum,\n",
    "    num_class=num_class,\n",
    "    num_order=num_order,\n",
    "    num_family=num_family,\n",
    "    num_genus=num_genus,\n",
    "    num_species=num_species\n",
    ")\n",
    "\n",
    "# 优化器与损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 训练循环\n",
    "model.train()\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        logits_phylum, logits_class, logits_order, logits_family, logits_genus, logits_species = model(\n",
    "            batch_x, \n",
    "            y=batch_y, \n",
    "            teacher_forcing=True\n",
    "        )\n",
    "\n",
    "        # 计算各层级的交叉熵损失\n",
    "        loss_phylum = criterion(logits_phylum, batch_y[:, 0])\n",
    "        loss_class = criterion(logits_class, batch_y[:, 1])\n",
    "        loss_order = criterion(logits_order, batch_y[:, 2])\n",
    "        loss_family = criterion(logits_family, batch_y[:, 3])\n",
    "        loss_genus = criterion(logits_genus, batch_y[:, 4])\n",
    "        loss_species = criterion(logits_species, batch_y[:, 5])\n",
    "\n",
    "        # 汇总各层级损失，或者可以加权\n",
    "        loss = (\n",
    "            loss_phylum + loss_class + loss_order +\n",
    "            loss_family + loss_genus + loss_species\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "Phylum: 3, Class: 33, Order: 19, Family: 116, Genus: 1295, Species: 6494\n",
      "Actual Labels:\n",
      "Phylum: 3, Class: 33, Order: 19, Family: 116, Genus: 1295, Species: 6494\n"
     ]
    }
   ],
   "source": [
    "# 将模型设置为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 从数据加载器中获取第一个批次的数据\n",
    "first_batch_x, first_batch_y = next(iter(dataloader))\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():  # 确保不计算梯度\n",
    "    logits_phylum, logits_class, logits_order, logits_family, logits_genus, logits_species = model(\n",
    "        first_batch_x, \n",
    "        y=first_batch_y, \n",
    "        teacher_forcing=False  # 在预测时通常不使用teacher forcing\n",
    "    )\n",
    "\n",
    "# 转换logits为标签索引\n",
    "pred_phylum = torch.argmax(logits_phylum, dim=1)\n",
    "pred_class = torch.argmax(logits_class, dim=1)\n",
    "pred_order = torch.argmax(logits_order, dim=1)\n",
    "pred_family = torch.argmax(logits_family, dim=1)\n",
    "pred_genus = torch.argmax(logits_genus, dim=1)\n",
    "pred_species = torch.argmax(logits_species, dim=1)\n",
    "\n",
    "# 打印第一个数据的预测和实际标签\n",
    "print(\"Predictions:\")\n",
    "print(f\"Phylum: {pred_phylum[0]}, Class: {pred_class[0]}, Order: {pred_order[0]}, Family: {pred_family[0]}, Genus: {pred_genus[0]}, Species: {pred_species[0]}\")\n",
    "print(\"Actual Labels:\")\n",
    "print(f\"Phylum: {first_batch_y[0, 0]}, Class: {first_batch_y[0, 1]}, Order: {first_batch_y[0, 2]}, Family: {first_batch_y[0, 3]}, Genus: {first_batch_y[0, 4]}, Species: {first_batch_y[0, 5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy:\n",
      "Phylum: 0.9939\n",
      "Class: 0.9923\n",
      "Order: 0.9912\n",
      "Family: 0.9878\n",
      "Genus: 0.9721\n",
      "Species: 0.8213\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 初始化用来存储准确率计算结果的变量\n",
    "accuracies = {\n",
    "    'phylum': 0,\n",
    "    'class': 0,\n",
    "    'order': 0,\n",
    "    'family': 0,\n",
    "    'genus': 0,\n",
    "    'species': 0\n",
    "}\n",
    "total_batches = len(dataloader)\n",
    "\n",
    "# 遍历数据加载器\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        logits_phylum, logits_class, logits_order, logits_family, logits_genus, logits_species = model(\n",
    "            batch_x, \n",
    "            y=batch_y, \n",
    "            teacher_forcing=False\n",
    "        )\n",
    "\n",
    "        # 计算每层的准确率\n",
    "        accuracies['phylum'] += (torch.argmax(logits_phylum, dim=1) == batch_y[:, 0]).float().mean()\n",
    "        accuracies['class'] += (torch.argmax(logits_class, dim=1) == batch_y[:, 1]).float().mean()\n",
    "        accuracies['order'] += (torch.argmax(logits_order, dim=1) == batch_y[:, 2]).float().mean()\n",
    "        accuracies['family'] += (torch.argmax(logits_family, dim=1) == batch_y[:, 3]).float().mean()\n",
    "        accuracies['genus'] += (torch.argmax(logits_genus, dim=1) == batch_y[:, 4]).float().mean()\n",
    "        accuracies['species'] += (torch.argmax(logits_species, dim=1) == batch_y[:, 5]).float().mean()\n",
    "\n",
    "# 计算平均准确率\n",
    "for key in accuracies:\n",
    "    accuracies[key] /= total_batches\n",
    "\n",
    "# 打印结果\n",
    "print(\"Training Set Accuracy:\")\n",
    "for level, acc in accuracies.items():\n",
    "    print(f\"{level.capitalize()}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'tax_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxonomy_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
