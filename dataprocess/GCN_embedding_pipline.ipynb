{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as pyg_nn\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from GCNFrame import Biodata, GCNmodel\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from Bio import SeqIO\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that the phylum labels are already prepared\n",
    "def prepare_phylum_labels(label_file):\n",
    "    # read label file\n",
    "    labels_df = pd.read_csv(label_file, sep='\\t', header=None, \n",
    "                           names=['sequence_id', 'phylum'])\n",
    "    \n",
    "    # convert labels to numeric values\n",
    "    label_encoder = LabelEncoder()\n",
    "    numeric_labels = label_encoder.fit_transform(labels_df['phylum'])\n",
    "    \n",
    "    # same the label mapping\n",
    "    label_mapping = dict(zip(label_encoder.classes_, \n",
    "                           range(len(label_encoder.classes_))))\n",
    "    \n",
    "    # save the numeric labels as a numpy array\n",
    "    np.savetxt('/root/autodl-tmp/TaxoChallenge/phylum_numeric_labels.txt', numeric_labels, fmt='%d')\n",
    "    \n",
    "    # save the label mapping\n",
    "    with open('/root/autodl-tmp/TaxoChallenge/phylum_label_mapping.txt', 'w') as f:\n",
    "        for phylum, idx in label_mapping.items():\n",
    "            f.write(f\"{phylum}\\t{idx}\\n\")\n",
    "    \n",
    "    return numeric_labels, label_mapping\n",
    "prepare_phylum_labels(\"/root/autodl-tmp/TaxoChallenge/ICTV_TaxoChallenge_id_phylum.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################## This is an example to train a two-classes model.#################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = Biodata(fasta_file=\"/root/autodl-tmp/TaxoChallenge/ICVTTaxoChallenge_43587.fa\", \n",
    "        label_file=\"/root/autodl-tmp/TaxoChallenge/phylum_numeric_labels.txt\",\n",
    "        feature_file=None)\n",
    "dataset = data.encode(thread=20)\n",
    "model = GCNmodel.model(label_num=20, other_feature_dim=0).to(device)\n",
    "GCNmodel.train(dataset, model, weighted_sampling=True, batch_size=16, model_name=\"/root/autodl-tmp/TaxoChallenge/GCN_model_43587.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BipartiteData Class\n",
    "class BipartiteData(Data):\n",
    "    def _add_other_feature(self, other_feature):\n",
    "        self.other_feature = other_feature\n",
    "\n",
    "    def __inc__(self, key, value):\n",
    "        if key == 'edge_index':\n",
    "            return torch.tensor([[self.x_src.size(0)], [self.x_dst.size(0)]])\n",
    "        else:\n",
    "            return super(BipartiteData, self).__inc__(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################extract vector embedding##################################\n",
    "def get_flattened_embeddings_from_model(model, data, device):\n",
    "    \"\"\"extract vector embedding from model and return the label if it exists\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # move data to device\n",
    "        x_f = data.x_src.to(device)\n",
    "        x_p = data.x_dst.to(device)\n",
    "        edge_index_forward = data.edge_index[:, ::2].to(device)\n",
    "        edge_index_backward = data.edge_index[[1, 0], :][:, 1::2].to(device)\n",
    "\n",
    "        # primary node feature processing\n",
    "        if model.pnode_nn:\n",
    "            x_p = torch.reshape(x_p, (-1, model.pnode_num * model.pnode_dim))\n",
    "            x_p = model.pnode_d(x_p)\n",
    "            x_p = torch.reshape(x_p, (-1, model.node_hidden_dim))\n",
    "        else:\n",
    "            x_p = torch.reshape(x_p, (-1, model.pnode_dim))\n",
    "\n",
    "        # feature node processing\n",
    "        if model.fnode_nn:\n",
    "            x_f = torch.reshape(x_f, (-1, model.fnode_num))\n",
    "            x_f = model.fnode_d(x_f)\n",
    "            x_f = torch.reshape(x_f, (-1, model.node_hidden_dim))\n",
    "        else:\n",
    "            x_f = torch.reshape(x_f, (-1, 1))\n",
    "\n",
    "        # add label embedding if it exists\n",
    "        if hasattr(model, 'label_embedding') and hasattr(data, 'y'):\n",
    "            label_embedding = model.label_embedding(data.y)\n",
    "            x_p = x_p + label_embedding.unsqueeze(1).expand(-1, x_p.size(1), -1)\n",
    "\n",
    "        # GCN layers\n",
    "        for i in range(model.gcn_layer_num):\n",
    "            x_p = model.gconvs_1[i]((x_f, x_p), edge_index_forward)\n",
    "            x_p = F.relu(x_p)\n",
    "            x_f = model.gconvs_2[i]((x_p, x_f), edge_index_backward)\n",
    "            x_f = F.relu(x_f)\n",
    "            if not i == model.gcn_layer_num - 1:\n",
    "                x_p = model.lns[i](x_p)\n",
    "                x_f = model.lns[i](x_f)\n",
    "\n",
    "        # convolutional layers\n",
    "        x_p = torch.reshape(x_p, (-1, model.gcn_dim, model.pnode_num))\n",
    "        for i in range(model.cnn_layer_num):\n",
    "            x_p = model.convs[i](x_p)\n",
    "            x_p = F.relu(x_p)\n",
    "\n",
    "        # flatten to 2D tensor\n",
    "        flattened_embedding = x_p.flatten(start_dim=1)\n",
    "\n",
    "        # return flattened embedding and label if it exists\n",
    "        return flattened_embedding.cpu(), data.y.cpu() if hasattr(data, 'y') else None\n",
    "\n",
    "\n",
    "def get_flattened_dataset_embeddings(dataset, model_path, batch_size=8, device=None):\n",
    "    \"\"\"get flattened embeddings for the dataset and return the labels if they exist\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Processing dataset with {len(dataset)} samples...\")\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        follow_batch=['x_src', 'x_dst'])\n",
    "\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Processing batches\"):\n",
    "            try:\n",
    "                # extract flattened embeddings and labels\n",
    "                embedding, label = get_flattened_embeddings_from_model(model, batch, device)\n",
    "                embeddings.append(embedding)\n",
    "\n",
    "                if label is not None:\n",
    "                    labels.append(label)\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "                if batch_size > 1:\n",
    "                    print(\"Reducing batch size and retrying...\")\n",
    "                    return get_flattened_dataset_embeddings(dataset, model_path, batch_size=batch_size // 2, device=device)\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    print(\"Concatenating flattened embeddings...\")\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "\n",
    "    if labels:\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "        return embeddings, labels\n",
    "\n",
    "    return embeddings, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your own path\n",
    "fasta_file = '/root/autodl-tmp/1000-ICTV/virus_new_sorted_1000.fasta'  # fasta path\n",
    "phylum_file = '/root/autodl-tmp/workspace/ICTV/1000/id-phylum-1000.txt'     # phylum lable path\n",
    "model_path = '/root/autodl-tmp/1000-ICTV/GCN_model.pt'  # model path\n",
    "save_path = '/root/autodl-tmp/1000-ICTV/embeddings_with_phylum_1000_lowdimension_labels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################get vector embedding############################\n",
    "flattened_embeddings, labels= get_flattened_dataset_embeddings(dataset, model_path, batch_size=32)\n",
    "print(f\"Flattened embeddings shape: {flattened_embeddings.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################umap Dimensionality Reduction and Visualization################################\n",
    "def visualize_embeddings_with_umap(flattened_embeddings, labels=labels, n_neighbors=15, min_dist=0.1, n_components=2, metric='euclidean'):\n",
    "\n",
    "    print(\"Starting UMAP dimensionality reduction...\")\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, n_components=n_components, metric=metric)\n",
    "    embeddings_2d = reducer.fit_transform(flattened_embeddings)\n",
    "\n",
    "    print(\"Visualizing embeddings...\")\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    if labels is not None:\n",
    "        scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=labels, cmap='Spectral', s=5, alpha=0.7)\n",
    "        plt.colorbar(scatter, label=\"Labels\")\n",
    "    else:\n",
    "        plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=5, alpha=0.7)\n",
    "\n",
    "    plt.title(\"UMAP Visualization of Embeddings\")\n",
    "    plt.xlabel(\"UMAP Dimension 1\")\n",
    "    plt.ylabel(\"UMAP Dimension 2\")\n",
    "    plt.show()\n",
    "\n",
    "# visualization\n",
    "visualize_embeddings_with_umap(flattened_embeddings, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################extract matrix embedding##################################\n",
    "def get_matrix_embeddings_from_model(model, data, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 将move data to device\n",
    "        x_f = data.x_src.to(device)\n",
    "        x_p = data.x_dst.to(device)\n",
    "        edge_index_forward = data.edge_index[:, ::2].to(device)\n",
    "        edge_index_backward = data.edge_index[[1, 0], :][:, 1::2].to(device)\n",
    "\n",
    "        # primary node feature processing\n",
    "        if model.pnode_nn:\n",
    "            x_p = torch.reshape(x_p, (-1, model.pnode_num * model.pnode_dim))\n",
    "            x_p = model.pnode_d(x_p)\n",
    "            x_p = torch.reshape(x_p, (-1, model.node_hidden_dim))\n",
    "        else:\n",
    "            x_p = torch.reshape(x_p, (-1, model.pnode_dim))\n",
    "\n",
    "        # feature node processing\n",
    "        if model.fnode_nn:\n",
    "            x_f = torch.reshape(x_f, (-1, model.fnode_num))\n",
    "            x_f = model.fnode_d(x_f)\n",
    "            x_f = torch.reshape(x_f, (-1, model.node_hidden_dim))\n",
    "        else:\n",
    "            x_f = torch.reshape(x_f, (-1, 1))\n",
    "\n",
    "        # add label embedding if it exists\n",
    "        if hasattr(model, 'label_embedding') and hasattr(data, 'y'):\n",
    "            label_embedding = model.label_embedding(data.y)\n",
    "            x_p = x_p + label_embedding.unsqueeze(1).expand(-1, x_p.size(1), -1)\n",
    "\n",
    "        # GCN layers\n",
    "        for i in range(model.gcn_layer_num):\n",
    "            x_p = model.gconvs_1[i]((x_f, x_p), edge_index_forward)\n",
    "            x_p = F.relu(x_p)\n",
    "            x_f = model.gconvs_2[i]((x_p, x_f), edge_index_backward)\n",
    "            x_f = F.relu(x_f)\n",
    "            if not i == model.gcn_layer_num - 1:\n",
    "                x_p = model.lns[i](x_p)\n",
    "                x_f = model.lns[i](x_f)\n",
    "\n",
    "        # convolutional layers\n",
    "        x_p = torch.reshape(x_p, (-1, model.gcn_dim, model.pnode_num))\n",
    "        for i in range(model.cnn_layer_num):\n",
    "            x_p = model.convs[i](x_p)\n",
    "            x_p = F.relu(x_p)\n",
    "\n",
    "        # return matrix embedding and label if it exists\n",
    "        return x_p.cpu(), data.y.cpu() if hasattr(data, 'y') else None\n",
    "\n",
    "\n",
    "def get_matrix_dataset_embeddings(dataset, model_path, fasta_ids, batch_size=8, device=None):\n",
    "    \"\"\"Get matrix-form embeddings for the entire dataset and store them as a dictionary including fasta sequence IDs\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    model = torch.load(model_path, map_location=device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Processing dataset with {len(dataset)} samples...\")\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=False,\n",
    "                        follow_batch=['x_src', 'x_dst'])\n",
    "\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fasta_id_index = 0  # for tracking the current fasta ID\n",
    "\n",
    "        for batch in tqdm(loader, desc=\"Processing batches\"):\n",
    "            try:\n",
    "                # extract matrix embeddings and labels\n",
    "                embedding, label = get_matrix_embeddings_from_model(model, batch, device)\n",
    "\n",
    "                # use fasta IDS as keys to store embeddings in the dictionary\n",
    "                for idx in range(embedding.shape[0]):\n",
    "                    contig_id = fasta_ids[fasta_id_index]\n",
    "                    embeddings_dict[contig_id] = embedding[idx].numpy()\n",
    "                    fasta_id_index += 1\n",
    "\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error processing batch: {e}\")\n",
    "                if batch_size > 1:\n",
    "                    print(\"Reducing batch size and retrying...\")\n",
    "                    return get_matrix_dataset_embeddings(dataset, model_path, fasta_ids, batch_size=batch_size // 2, device=device)\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path\n",
    "fasta_file = '/root/autodl-tmp/TaxoChallenge/ICVTTaxoChallenge_43587.fa'  # fasta path\n",
    "phylum_file = '/root/autodl-tmp/TaxoChallenge/ICTV_TaxoChallenge_id_phylum.txt'     # phylum label path\n",
    "model_path = '/root/autodl-tmp/TaxoChallenge/GCN_model_43587.pt'  # model path\n",
    "save_path = '/root/autodl-tmp/TaxoChallenge/embeddings_with_phylum_dict_matrix.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################extract fasta id##################################\n",
    "fasta_file = \"/root/autodl-tmp/TaxoChallenge/ICVTTaxoChallenge_43587.fa\"\n",
    "fasta_ids = [record.id for record in SeqIO.parse(fasta_file, \"fasta\")]\n",
    "print(f\"Extracted {len(fasta_ids)} IDs from {fasta_file}\")\n",
    "print(f\"First 5 IDs: {fasta_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################extreact matrix embedding result##################################\n",
    "matrix_embeddings= get_matrix_dataset_embeddings(dataset, model_path, fasta_ids, batch_size=32)\n",
    "print(f\"Flattened embeddings shape: {matrix_embeddings}.keys()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################save as.pkl##################################\n",
    "save_path = '/root/autodl-tmp/TaxoChallenge/embeddings_with_phylum_43587_matrix.pkl'\n",
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(matrix_embeddings, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
